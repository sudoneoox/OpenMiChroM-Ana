{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def extract_metrics(log_entry, reduction_technique):\n",
    "    pattern = r'method: (\\w+).*metric: (\\w+).*norm: (\\w+).*Silhouette Score: ([\\d.]+).*Calinski-Harabasz Index: ([\\d.]+).*Davies-Bouldin Index: ([\\d.]+)'\n",
    "    match = re.search(pattern, log_entry, re.DOTALL)\n",
    "    if match:\n",
    "        return {\n",
    "            'Reduction Technique': reduction_technique,\n",
    "            'Method': match.group(1),\n",
    "            'Metric': match.group(2),\n",
    "            'Norm': match.group(3),\n",
    "            'Silhouette Score': float(match.group(4)),\n",
    "            'Calinski-Harabasz Index': float(match.group(5)),\n",
    "            'Davies-Bouldin Index': float(match.group(6))\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def process_log_file(log_file):\n",
    "    reduction_technique = os.path.basename(os.path.dirname(log_file))\n",
    "    with open(log_file, 'r') as file:\n",
    "        log_content = file.read()\n",
    "    log_entries = log_content.split('==================================================')\n",
    "    metrics = [extract_metrics(entry, reduction_technique) for entry in log_entries if 'Clustering Metrics' in entry]\n",
    "    return [m for m in metrics if m is not None]\n",
    "\n",
    "def analyze_metrics(df):\n",
    "    best_silhouette = df.loc[df['Silhouette Score'].idxmax()]\n",
    "    best_calinski = df.loc[df['Calinski-Harabasz Index'].idxmax()]\n",
    "    best_davies = df.loc[df['Davies-Bouldin Index'].idxmin()]\n",
    "    \n",
    "    print(\"Best combinations:\")\n",
    "    print(f\"Silhouette Score: {best_silhouette[['Reduction Technique', 'Method', 'Metric', 'Norm', 'Silhouette Score']]}\")\n",
    "    print(f\"Calinski-Harabasz Index: {best_calinski[['Reduction Technique', 'Method', 'Metric', 'Norm', 'Calinski-Harabasz Index']]}\")\n",
    "    print(f\"Davies-Bouldin Index: {best_davies[['Reduction Technique', 'Method', 'Metric', 'Norm', 'Davies-Bouldin Index']]}\")\n",
    "\n",
    "\n",
    "def plot_combined_heatmap(df, output_dir, metrics_to_plot='all'):\n",
    "    all_metrics = ['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index']\n",
    "    \n",
    "    if metrics_to_plot == 'all':\n",
    "        metrics = all_metrics\n",
    "    elif metrics_to_plot in all_metrics:\n",
    "        metrics = [metrics_to_plot]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric specified. Choose 'all' or one of 'Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index'\")\n",
    "\n",
    "    for technique in df['Reduction Technique'].unique():\n",
    "        df_technique = df[df['Reduction Technique'] == technique]\n",
    "        \n",
    "        fig, axes = plt.subplots(len(metrics), 1, figsize=(20, 8 * len(metrics)))\n",
    "        if len(metrics) == 1:\n",
    "            axes = [axes]  # Make axes iterable when there's only one subplot\n",
    "        # fig.suptitle(f'Clustering Performance for {technique}', fontsize=24, y=0.95)\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            pivot = df_technique.groupby(['Method', 'Metric', 'Norm'])[metric].mean().unstack(level=[1, 2])\n",
    "            \n",
    "            if metric == 'Davies-Bouldin Index':\n",
    "                cmap = 'YlOrRd_r'\n",
    "                interpretation = 'Lower is better'\n",
    "                vmin = 0\n",
    "                vmax = df[metric].max()\n",
    "                best_value = pivot.min().min()\n",
    "                worst_value = pivot.max().max()\n",
    "            elif metric == 'Silhouette Score':\n",
    "                cmap = 'YlGnBu'\n",
    "                interpretation = 'Higher is better'\n",
    "                vmin = 0\n",
    "                vmax = 1\n",
    "                best_value = pivot.max().max()\n",
    "                worst_value = pivot.min().min()\n",
    "            else:  # Calinski-Harabasz Index\n",
    "                cmap = 'YlGnBu'\n",
    "                interpretation = 'Higher is better'\n",
    "                vmin = None\n",
    "                vmax = None\n",
    "                best_value = pivot.max().max()\n",
    "                worst_value = pivot.min().min()\n",
    "            \n",
    "            sns.heatmap(pivot, annot=True, cmap=cmap, fmt='.2f', \n",
    "                        cbar_kws={'label': metric}, ax=axes[i], annot_kws={'size': 10},\n",
    "                        vmin=vmin, vmax=vmax)\n",
    "            \n",
    "            # Highlight the best score\n",
    "            best_indices = np.where(pivot == best_value)\n",
    "            for row, col in zip(*best_indices):\n",
    "                axes[i].add_patch(plt.Rectangle((col, row), 1, 1, fill=False, edgecolor='lime', lw=3))\n",
    "            \n",
    "            # Highlight the worst score\n",
    "            worst_indices = np.where(pivot == worst_value)\n",
    "            for row, col in zip(*worst_indices):\n",
    "                axes[i].add_patch(plt.Rectangle((col, row), 1, 1, fill=False, edgecolor='red', lw=3))\n",
    "            \n",
    "            axes[i].set_title(f'{metric}\\n{interpretation}', fontsize=20)\n",
    "            axes[i].set_xlabel('Metric, Norm', fontsize=16)\n",
    "            axes[i].set_ylabel('Method', fontsize=16)\n",
    "            \n",
    "            axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "            axes[i].set_yticklabels(axes[i].get_yticklabels(), fontsize=12)\n",
    "            \n",
    "            for t in axes[i].texts:\n",
    "                t.set_fontsize(12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = f'{technique}_clustering_performance_heatmap'\n",
    "        if metrics_to_plot != 'all':\n",
    "            filename += f'_{metrics_to_plot.replace(\" \", \"_\").lower()}'\n",
    "        plt.savefig(os.path.join(output_dir, f'{filename}.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Create a separate legend for interpretation\n",
    "    fig_legend = plt.figure(figsize=(10, 5))\n",
    "    ax_legend = fig_legend.add_subplot(111)\n",
    "    ax_legend.axis('off')\n",
    "    ax_legend.text(0.1, 0.8, \"Interpretation:\", fontweight='bold', fontsize=14)\n",
    "    ax_legend.text(0.1, 0.6, \"Silhouette Score & Calinski-Harabasz Index: Higher is better\", fontsize=12)\n",
    "    ax_legend.text(0.1, 0.4, \"Davies-Bouldin Index: Lower is better\", fontsize=12)\n",
    "    ax_legend.text(0.1, 0.2, \"Green border: Best score for each metric\", fontsize=12)\n",
    "    ax_legend.text(0.1, 0.0, \"Red border: Worst score for each metric\", fontsize=12)\n",
    "    plt.savefig(os.path.join(output_dir, 'heatmap_legend.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_normalized_scores(df_normalized, output_dir):\n",
    "    # Define color scheme for methods\n",
    "    method_colors = {'single': 'red', 'complete': 'blue', 'average': 'green', 'weighted': 'purple'}\n",
    "    \n",
    "    for technique in df_normalized['Reduction Technique'].unique():\n",
    "        plt.figure(figsize=(30, 20))\n",
    "        \n",
    "        df_tech = df_normalized[df_normalized['Reduction Technique'] == technique]\n",
    "        \n",
    "        for method in df_tech['Method'].unique():\n",
    "            df_method = df_tech[df_tech['Method'] == method]\n",
    "            plt.scatter(df_method['Silhouette Score'], \n",
    "                        df_method['Calinski-Harabasz Index'],\n",
    "                        c=df_method['Davies-Bouldin Index'],\n",
    "                        s=200,  # Increased marker size\n",
    "                        cmap='viridis_r',\n",
    "                        marker='o',\n",
    "                        edgecolors=method_colors[method],\n",
    "                        linewidth=2,\n",
    "                        alpha=0.7,\n",
    "                        label=method)\n",
    "        \n",
    "        plt.colorbar(label='Davies-Bouldin Index (Lower is better)')\n",
    "        \n",
    "        plt.title(f'Normalized Clustering Performance - {technique}', fontsize=20)\n",
    "        plt.xlabel('Silhouette Score (Higher is better)', fontsize=20)\n",
    "        plt.ylabel('Calinski-Harabasz Index (Higher is better)', fontsize=14)\n",
    "        \n",
    "        plt.legend(title='Method', title_fontsize=12, fontsize=10)\n",
    "        \n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Annotate best performers\n",
    "        best_silhouette = df_tech.loc[df_tech['Silhouette Score'].idxmax()]\n",
    "        best_calinski = df_tech.loc[df_tech['Calinski-Harabasz Index'].idxmax()]\n",
    "        best_davies = df_tech.loc[df_tech['Davies-Bouldin Index'].idxmin()]\n",
    "        \n",
    "        for best in [best_silhouette, best_calinski, best_davies]:\n",
    "            plt.annotate(f\"{best['Method']}\\n{best['Metric']}-{best['Norm']}\",\n",
    "                         (best['Silhouette Score'], best['Calinski-Harabasz Index']),\n",
    "                         xytext=(5, 5), textcoords='offset points', fontsize=16,\n",
    "                         bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=1.0),\n",
    "                         arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.3\"))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'normalized_clustering_performance_{technique}.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    # Create a legend figure\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for method, color in method_colors.items():\n",
    "        plt.scatter([], [], c=color, label=method, s=100)\n",
    "    plt.legend(title='Method', title_fontsize=14, fontsize=12, loc='center')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_dir, 'method_legend.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "def plot_reduction_technique_summary(df, output_dir, metrics_to_plot='all', central_tendency='median'):\n",
    "    all_metrics = ['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index']\n",
    "    \n",
    "    if metrics_to_plot == 'all':\n",
    "        metrics = all_metrics\n",
    "    elif metrics_to_plot in all_metrics:\n",
    "        metrics = [metrics_to_plot]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric specified. Choose 'all' or one of 'Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index'\")\n",
    "\n",
    "    if central_tendency not in ['mean', 'median']:\n",
    "        raise ValueError(\"Invalid central tendency specified. Choose 'mean' or 'median'\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(metrics), figsize=(8 * len(metrics), 8))\n",
    "    if len(metrics) == 1:\n",
    "        axes = [axes]\n",
    "    fig.suptitle(f'Summary of Clustering Performance Across Reduction Techniques\\n(Central Tendency: {central_tendency.capitalize()})', fontsize=24)\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Prepare data for box plot\n",
    "        plot_data = []\n",
    "        labels = []\n",
    "        for technique in df['Reduction Technique'].unique():\n",
    "            plot_data.append(df[df['Reduction Technique'] == technique][metric])\n",
    "            labels.append(technique)\n",
    "        \n",
    "        # Create box plot with extended whiskers\n",
    "        bp = ax.boxplot(plot_data, tick_labels=labels, patch_artist=True, whis=[0, 100])\n",
    "        \n",
    "        # Customize box colors\n",
    "        for box in bp['boxes']:\n",
    "            box.set(facecolor='lightblue', edgecolor='blue', alpha=0.7)\n",
    "        \n",
    "        # Customize median line\n",
    "        for median in bp['medians']:\n",
    "            median.set(color='red', linewidth=2)\n",
    "        \n",
    "        # Remove cap lines\n",
    "        for cap in bp['caps']:\n",
    "            cap.set(visible=True)\n",
    "        \n",
    "        # Extend whiskers to full range\n",
    "        for whisker in bp['whiskers']:\n",
    "            whisker.set(linestyle='-', color='black')\n",
    "        \n",
    "        ax.set_ylabel('Score', fontsize=14)\n",
    "        ax.set_title(metric, fontsize=18)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right', fontsize=12)\n",
    "        \n",
    "        if metric == 'Davies-Bouldin Index':\n",
    "            ax.invert_yaxis()  # Lower is better for Davies-Bouldin Index\n",
    "        \n",
    "        # Add central tendency value as text\n",
    "        for i, d in enumerate(plot_data):\n",
    "            if central_tendency == 'mean':\n",
    "                value = np.mean(d)\n",
    "            else:\n",
    "                value = np.median(d)\n",
    "            ax.text(i+1, value, f'{value:.2f}', horizontalalignment='center', \n",
    "                    verticalalignment='bottom', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = 'reduction_technique_summary_boxplot'\n",
    "    if metrics_to_plot != 'all':\n",
    "        filename += f'_{metrics_to_plot.replace(\" \", \"_\").lower()}'\n",
    "    filename += f'_{central_tendency}'\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(output_dir, f'{filename}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Additional plot saving as per your code\n",
    "    plt.tight_layout()\n",
    "    filename = 'reduction_technique_summary'\n",
    "    if metrics_to_plot != 'all':\n",
    "        filename += f'_{metrics_to_plot.replace(\" \", \"_\").lower()}'\n",
    "    filename += f'_{central_tendency}'\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(output_dir, f'{filename}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()    \n",
    "    \n",
    "def plot_combined_visualization(df, output_dir, metrics_to_plot='all', central_tendency='median'):\n",
    "    # First, create the heatmaps\n",
    "    plot_combined_heatmap(df, output_dir, metrics_to_plot)\n",
    "    \n",
    "    # Then, create the summary plot\n",
    "    plot_reduction_technique_summary(df, output_dir, metrics_to_plot, central_tendency)\n",
    "    \n",
    "    # Now, create a combined figure\n",
    "    techniques = df['Reduction Technique'].unique()\n",
    "    \n",
    "    all_metrics = ['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index']\n",
    "    if metrics_to_plot == 'all':\n",
    "        metrics = all_metrics\n",
    "    elif metrics_to_plot in all_metrics:\n",
    "        metrics = [metrics_to_plot]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric specified. Choose 'all' or one of 'Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index'\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 10 + 5 * len(metrics)))\n",
    "    gs = fig.add_gridspec(2, len(techniques))\n",
    "    \n",
    "    for i, technique in enumerate(techniques):\n",
    "        # Add heatmap\n",
    "        heatmap_filename = f'{technique}_clustering_performance_heatmap'\n",
    "        if metrics_to_plot != 'all':\n",
    "            heatmap_filename += f'_{metrics_to_plot.replace(\" \", \"_\").lower()}'\n",
    "        heatmap_filename += '.png'\n",
    "        heatmap_img = plt.imread(os.path.join(output_dir, heatmap_filename))\n",
    "        ax_heatmap = fig.add_subplot(gs[0, i])\n",
    "        ax_heatmap.imshow(heatmap_img)\n",
    "        ax_heatmap.axis('off')\n",
    "        ax_heatmap.set_title(technique, fontsize=20)\n",
    "    \n",
    "    # Add summary plot\n",
    "    summary_filename = 'reduction_technique_summary'\n",
    "    if metrics_to_plot != 'all':\n",
    "        summary_filename += f'_{metrics_to_plot.replace(\" \", \"_\").lower()}'\n",
    "    summary_filename += f'_{central_tendency}.png'\n",
    "    summary_img = plt.imread(os.path.join(output_dir, summary_filename))\n",
    "    ax_summary = fig.add_subplot(gs[1, :])\n",
    "    ax_summary.imshow(summary_img)\n",
    "    ax_summary.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    combined_filename = 'combined_visualization'\n",
    "    if metrics_to_plot != 'all':\n",
    "        combined_filename += f'_{metrics_to_plot.replace(\" \", \"_\").lower()}'\n",
    "    combined_filename += f'_{central_tendency}.png'\n",
    "    plt.savefig(os.path.join(output_dir, combined_filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    \n",
    "def run():\n",
    "    log_files = [\n",
    "        'Analysis/MDS/dimensionality_reduction_log.txt',\n",
    "        'Analysis/PCA/dimensionality_reduction_log.txt',\n",
    "        'Analysis/SVD/dimensionality_reduction_log.txt',\n",
    "        'Analysis/t-sne/dimensionality_reduction_log.txt',\n",
    "        'Analysis/UMAP/dimensionality_reduction_log.txt'\n",
    "    ]\n",
    "\n",
    "    output_dir = './Analysis/reduction-techniques'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_log_file, log_file) for log_file in log_files]\n",
    "        all_metrics = [metric for future in as_completed(futures) for metric in future.result()]\n",
    "\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    # Handle duplicate entries\n",
    "    df = df.groupby(['Reduction Technique', 'Method', 'Metric', 'Norm']).mean().reset_index()\n",
    "    \n",
    "    df.to_csv(os.path.join(output_dir, 'clustering_metrics_summary.csv'), index=False)\n",
    "\n",
    "    analyze_metrics(df)\n",
    "    all_metrics = ['Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index', 'all']\n",
    "\n",
    "    plot_combined_visualization(df, output_dir, metrics_to_plot=all_metrics[0], central_tendency='median')\n",
    "    # Plot normalized scores\n",
    "    df_normalized = df.copy()\n",
    "    for col in ['Silhouette Score', 'Calinski-Harabasz Index']:\n",
    "        df_normalized[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "    df_normalized['Davies-Bouldin Index'] = 1 - (df['Davies-Bouldin Index'] - df['Davies-Bouldin Index'].min()) / (df['Davies-Bouldin Index'].max() - df['Davies-Bouldin Index'].min())\n",
    "\n",
    "    plot_normalized_scores(df_normalized, output_dir)\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MICROM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
